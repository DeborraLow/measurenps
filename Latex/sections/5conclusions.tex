\section{Conclusions}
\label{sec:conclusion}

The empirical studies in Sections~\ref{sec:corpusstudies} and~\ref{sec:experimental} confirm the theoretical model proposed in Section~\ref{sec:germanmeasurenps}, which predicted prototype effects and exemplar effects to jointly determine which of the two alternating constructions is chosen.
More specifically, the pre-study and the main study provided evidence that the NAC constructions favour more strongly grammaticalised measure nouns, modification by cardinals, and styles where the genitive is underrepresented and the text is less coherently and elaborately written, as captured in the \textit{Badness} variable.%
\footnote{Although, as pointed out in Section~\ref{sec:mainstudyinterpretation}, the \textit{Badness} effect is weak and not detected in the pre-study, probably as a consequence of its weakness.}
The overall convergence between the pre-study and the main study and also the expected result for \textit{Measurecase} in line with previous research \citep{Zimmer2015} -- although it was only a control variable here -- strengthen the validity of this study even without the experimental validation.

While the results do not \textit{prove} -- due to the intrinsic equivalence of prototype and exemplar models with respect to the output they produce -- that the model proposed in Section~\ref{sec:germanmeasurenps} is congruent with any speaker's mental representation, the two attraction features (\textit{Kindattraction} and \textit{Measureattraction}) are virtually impossible to conceive of as prototype effects.
As discussed in Section~\ref{sec:cogocl}, it is unnecessary to follow an extreme route, be it radical prototype theory or radical exemplar theory given recent developments in cognitive science and (less prominently) cognitive linguistics.
While it is surely an intentionally overstated comment, \citet[15]{Kapatsinski2014} even suggests that ``[i]n the extreme, some speakers’ heads could host exemplar models, and some could contain fairly abstract grammars, and the produced output would be essentially identical''.
If this is the case (even to a less extreme degree), corpora only provide (still informative) pooled data averaged over speaker grammars with varying levels of abstraction.
Clearly, more research is required in this direction.

Another important aspect of the research presented here is the validation of the results derived from corpus data in two experimental paradigms.
While such cross-validations have been done (with varying success, see Section~\ref{sec:cogocl}) for over a decade, they have not yet become standard procedure.
As \citet[3--4]{DivjakEa2016a} put it:

\begin{quote}
  There are now a number of published multivariate models that use data[,] extracted from corpora [\ldots] to predict the choice for one morpheme, lexeme or construction over another.
  However, [\ldots] only a small number of these corpus-based studies have been cross-validated [\ldots].
  Of these cross- validated studies, few have directly evaluated the prediction accuracy of a complex, multivariate corpus-based model on humans using authentic corpus sentences [\ldots].
\end{quote}

The question now arises whether convergence was reached in the present case or not.
The answer is a clear yes.
The predictions made by the corpus-based model were a significant factor, both in the more explicit paradigm (forced choice) and the implicit paradigm (self-paced reading).
This shows that the model indeed predicts the variant which language users expect.
The overall effect as measured in the $R^2$ was weak (roughly 0.2) in both cases, however.
While part of this could be traced back to one suboptimally chosen stimulus, we really need to consider what kind of convergence we expect to see between corpus data and experiments.
The main corpus study had $R^2_m=0.409$ and $R^2_c=0.495$, which is good but not anywhere near a perfect fit.
With the added inter-speaker variability brought into play by the experimental setup (compared to the averaging across thousands of speakers in the corpus study), a perfect fit cannot be expected.
Like many phenomena in German which are often called \textit{Zweifelsfälle} (`cases of doubt') in the traditional literature \citep{Duden09,Klein2009} the MNP alternation is one of the cases where speakers very often have no clear intuition and a lot of free variation seems to be involved.
Rarely do speakers feel that one alternative is clearly odd or bad.
Additionally, cases of doubt involving the genitive are often a matter of fierce normative public debate, and especially the forced choice paradigm does not effectively prevent participants from making normative judgements.
This might even account for the slightly better fit in the self-paced reading experiment, where normative considerations are suppressed.
Thus, the present study shows that what counts as convergence between corpus and experimental results should be gauged considering the nature of the phenomenon at hand, the source of the corpus data, and the experimental paradigm.
Clearly, more case studies using diverse and different corpora are needed, and it should become standard practice to cross-validate them using experimental methods.
Given that a single failure to achieve convergence does not provide conclusive evidence for divergence, many more studies need to be published to the point that meta-analysis becomes possible.%
\footnote{This is even more vital considering the variation in results from experimental work.
See, for example, the impressive list of different reading time results from ten papers on Chinese relative clause processing in \citet[8]{Vasishth2015}.}

On a larger methodological scale, this paper also makes a number of contributions.
The statistical model was a true multilevel model (see Section~\ref{sec:itemandexemplareffects} and Section~\ref{sec:mainstudystatisticalmodel}), demonstrating how multilevel modelling helps to specify complex hierarchies of abstract features, item-specific tendencies, and exemplar effects at the level of observations (sentences; first level) and lemmas (second level).
While \cite{Gries2015} still calls mixed models ``underused'' in corpus linguistics, multilevel models are consequently at least equally underused tools.
At the same time, the effects of overparametrisation of mixed models with varying slopes as criticised by \cite{BatesEa2015a} were demonstrated.
Furthermore, fitting an additive model to the reading time data did not improve the fit as there were no non-linearities in the data.
While \cite{DivjakEa2016} also use attested sentences, they find that an additive model helped to deal with non-linearities.
This is clearly another area where only more studies can lead to clarification.
Finally, much like \cite{Dabrowska2014} found that speakers' knowledge of collocations was not matched by a set of standard measures of collocation strength extracted from corpora, a simple quotient based on raw frequencies for the attraction strength performed much better in the present study compared to collexeme strength (see Section~\ref{sec:corpusstudies}).
While this does not allow the conclusion that collexeme strength has no cognitive reality, it might indicate that for measuring attraction effects exerted by non-alternating constructions on alternating constructions, other measures might be more appropriate.

Besides the methodological aspects mentioned above, future work could extend the validity of the results presented here through a more in-depth look at stylistic or register effects, for example using the new Biber-style annotations \citep{Biber1988} which will be released with a new version of the DECOW corpus soon.
Also, regional variation as a potentially influencing factor was already mentioned in Section~\ref{sec:prototypeeffects}.
As it would be infeasible to examine this with existing corpora, experimental work with participants from various regions might be the ideal approach.
A reviewer also pointed out that strongly lexicalised adjective-noun combinations like \textit{schwarzer Tee} `black tea' might have a tendency to occur in the \NACa\ because they have more compound-like qualities, blocking strong case inflection in between them.
While this potential effect was impossible to incorporate into the present study, it could be integrated into future research on the phenomenon.

In closing, I want to point out that the so-called \textit{case of doubt} in German morpho-syntax -- like the measure noun phrase alternation -- are in fact ideal test cases for probabilistic modelling of alternation phenomena in cognitive linguistics.
Doing more research on them could help to provide answers to many of the fundamental and methodological issues raised here.
